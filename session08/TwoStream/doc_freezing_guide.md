# Fine-Tuning and Freezing Strategy: Quick Reference

## Overview
This guide explains the layer freezing strategy used in `finetune_twostream_ucf101.py` for adapting ImageNet pre-trained Two-Stream networks to UCF-101 action recognition.

## Core Concept: Freeze-Then-Unfreeze

```python
# Step 1: Freeze EVERYTHING (safe default)
for p in model.parameters():
    p.requires_grad = False

# Step 2: Selectively unfreeze what you need
for p in model.temporal.backbone.classifier.parameters():
    p.requires_grad = True  # Always train temporal classifier
```

**Why this pattern?**
- Prevents accidentally training frozen layers
- Makes it explicit what's trainable
- Easy to add more unfreezing logic

## The Three Training Modes

### Mode 1: Temporal-Only (Default) âš¡ FASTEST
```bash
python finetune_twostream_ucf101.py --ucf_root /data/UCF-101 --epochs 10
```

**What's trained:**
- âœ… Temporal classifier (fc6, fc7, fc8)
- âŒ Temporal conv layers (frozen)
- âŒ Spatial stream (entirely frozen)

**Performance:**
- Accuracy: 80-85%
- Training time: 6-8 hours
- Parameters trained: ~20M / 138M total

**When to use:** Fast baseline, debugging, proof-of-concept

---

### Mode 2: Temporal + First Conv ğŸ¯ RECOMMENDED
```bash
python finetune_twostream_ucf101.py --ucf_root /data/UCF-101 \
    --epochs 15 --unfreeze_temporal_backbone
```

**What's trained:**
- âœ… Temporal classifier
- âœ… Temporal first conv (adapts to optical flow input)
- âŒ Temporal conv2-5 (frozen)
- âŒ Spatial stream (frozen)

**Performance:**
- Accuracy: 83-88%
- Training time: 8-10 hours
- Parameters trained: ~25M / 138M total
- Accuracy gain: **+3-5%** over Mode 1

**When to use:** Production, best speed/accuracy trade-off

---

### Mode 3: Both Streams ğŸ† BEST ACCURACY
```bash
python finetune_twostream_ucf101.py --ucf_root /data/UCF-101 \
    --epochs 20 --spatial --unfreeze_spatial --fuse
```

**What's trained:**
- âœ… Temporal classifier + first conv
- âœ… Spatial classifier
- âœ… Optimizes fused logits
- âŒ Both conv backbones mostly frozen

**Performance:**
- Accuracy: 85-90% (matches original paper's 88%)
- Training time: 12-15 hours
- Parameters trained: ~40M / 138M total
- Accuracy gain: **+5-8%** over Mode 1

**When to use:** Research, benchmarking, maximum accuracy needed

---

## Why Temporal-Only Is Default

### 1. **Input Distribution Mismatch**
- Spatial stream: RGB frames (same as ImageNet) âœ…
- Temporal stream: Optical flow (different from ImageNet) âš ï¸
- â†’ Temporal needs more adaptation

### 2. **Task Relevance**
- Motion is THE discriminative feature for actions
- Temporal alone gets 81.2% (original paper)
- Spatial alone gets 73.0%
- â†’ Focus on temporal gives best ROI

### 3. **Efficiency**
- Training temporal only: 6-8 hours
- Training both: 12-15 hours
- â†’ 2x faster with only -3-5% accuracy

## Layer-by-Layer Breakdown

### VGG16 Architecture
```
Input (RGB or Flow)
    â†“
conv1 (64 filters)    â† Low-level: edges, corners
conv2 (128 filters)   â† Low-level: textures
    â†“
conv3 (256 filters)   â† Mid-level: patterns, simple shapes
conv4 (512 filters)   â† Mid-level: object parts
conv5 (512 filters)   â† High-level: semantics
    â†“
fc6 (4096)            â† Task-specific
fc7 (4096)            â† Task-specific
fc8 (101)             â† Action classes
```

### What to Freeze/Train

| Layer | Learns | Spatial Stream | Temporal Stream |
|-------|--------|---------------|-----------------|
| conv1-2 | Edges, textures | ğŸ”µ Freeze | ğŸŸ  Optional (--unfreeze_temporal_backbone) |
| conv3-4 | Patterns, shapes | ğŸ”µ Freeze | ğŸ”µ Freeze |
| conv5 | Semantics | ğŸ”µ Freeze | ğŸ”µ Freeze |
| fc6-7 | Task features | ğŸŸ  Optional (--unfreeze_spatial) | ğŸ”´ Always train |
| fc8 | Classifier | ğŸŸ  Optional | ğŸ”´ Always train |

Legend:
- ğŸ”´ Always train (requires_grad=True)
- ğŸŸ  Optional (flag-controlled)
- ğŸ”µ Freeze (requires_grad=False)

## Code Walkthrough

### The Freezing Logic (lines 445-456)
```python
# 1. Start with everything frozen
for p in model.parameters():
    p.requires_grad = False

# 2. Always train temporal classifier (fc layers)
for p in model.temporal.backbone.classifier.parameters():
    p.requires_grad = True

# 3. Optional: Unfreeze temporal first conv
#    Why? Flow input is different from RGB, needs adaptation
if args.unfreeze_temporal_backbone:
    for n, p in model.temporal.backbone.features.named_parameters():
        if n.startswith("0"):  # "0" = first conv block in VGG16.features
            p.requires_grad = True

# 4. Optional: Train spatial classifier too
if args.unfreeze_spatial:
    for p in model.spatial.backbone.classifier.parameters():
        p.requires_grad = True
```

### Why Check `n.startswith("0")`?

VGG16's `features` module naming:
```
features.0  = Conv2d (first conv) â† We want to unfreeze this
features.1  = ReLU
features.2  = Conv2d
features.3  = ReLU
...
features.28 = Conv2d (last conv)
```

So `n.startswith("0")` matches: `0.weight`, `0.bias` (first conv parameters)

## General Fine-Tuning Principles

### 1. Layer Hierarchy
- **Early layers**: General features (edges, textures) â†’ Usually freeze
- **Late layers**: Task-specific (semantics, classifier) â†’ Always train

### 2. Dataset Size
- **Large dataset** (>100k samples): Can train everything
- **Medium dataset** (10k-100k): Train top layers
- **Small dataset** (<10k): Freeze everything except classifier

**UCF-101** = 13k videos â†’ Medium dataset â†’ Train classifier + maybe high layers

### 3. Domain Similarity
- **Similar domains** (ImageNet â†’ CoCo): Can train more layers
- **Different domains** (ImageNet â†’ Medical): Freeze more layers
- **ImageNet â†’ Actions**: Moderate difference â†’ Freeze low, train high

### 4. Learning Rate Strategy
- **New layers** (classifier): High LR (1e-3 to 1e-2)
- **Pre-trained layers**: Low LR (1e-4 to 1e-5)
- **Frozen layers**: No LR (not in optimizer)

### 5. Gradual Unfreezing (Advanced)
```
Stage 1 (Epochs 1-5):   Train classifier only
Stage 2 (Epochs 6-10):  Unfreeze conv5 + classifier
Stage 3 (Epochs 11-20): Unfreeze conv4-5 + classifier
```

**Why?** Prevents randomly-initialized classifier from destroying pre-trained features with large gradients.

## Common Mistakes âŒ

### 1. Training Everything with High LR
```python
# BAD: Will destroy pre-trained features
optimizer = SGD(model.parameters(), lr=1e-2)
```
```python
# GOOD: Different LRs for different parts
optimizer = SGD([
    {'params': model.temporal.backbone.features.parameters(), 'lr': 1e-5},
    {'params': model.temporal.backbone.classifier.parameters(), 'lr': 1e-3}
])
```

### 2. Forgetting to Freeze
```python
# BAD: No freezing, trains everything
model = TwoStreamNet()
optimizer = SGD(model.parameters(), lr=1e-3)
```
```python
# GOOD: Explicit freezing
for p in model.parameters():
    p.requires_grad = False
for p in model.temporal.backbone.classifier.parameters():
    p.requires_grad = True
optimizer = SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)
```

### 3. Freezing Too Much
```python
# BAD: Only trains final layer (1000 params)
for p in model.parameters():
    p.requires_grad = False
model.temporal.backbone.classifier[-1].weight.requires_grad = True
```
Result: Underfits, can't learn complex patterns

## Expected Results on UCF-101

| Configuration | Top-1 Accuracy | Training Time | When to Use |
|--------------|---------------|---------------|-------------|
| Temporal classifier only | 80-83% | 6-8 hrs | Fast baseline |
| + First conv | 83-88% | 8-10 hrs | **Recommended** |
| + Spatial stream | 85-90% | 12-15 hrs | Maximum accuracy |
| Original paper (2014) | 88.0% | N/A | Benchmark |

## Debugging Tips

### Check What's Trainable
```python
trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
total = sum(p.numel() for p in model.parameters())
print(f"Trainable: {trainable:,} / {total:,} ({100*trainable/total:.1f}%)")
```

Expected outputs:
- Temporal classifier only: ~20M / 138M (14%)
- + First conv: ~25M / 138M (18%)
- + Spatial: ~40M / 138M (29%)

### Verify Gradients
```python
# After loss.backward(), check that frozen layers have no gradients
for n, p in model.named_parameters():
    if p.requires_grad and p.grad is None:
        print(f"WARNING: {n} has no gradient!")
```

### Monitor Per-Layer Gradient Norms
```python
for n, p in model.named_parameters():
    if p.grad is not None:
        grad_norm = p.grad.norm().item()
        print(f"{n}: {grad_norm:.2e}")
```

If frozen layers have gradients â†’ Bug in freezing logic!

## Summary Table

| Strategy | Frozen | Trainable | Accuracy | Time |
|----------|--------|-----------|----------|------|
| **Temporal-only** | Spatial + Temporal conv | Temporal fc | 80-83% | 6-8h |
| **+ First conv** | Spatial + Temporal conv2-5 | Temporal conv1 + fc | 83-88% | 8-10h |
| **+ Spatial** | Temporal/Spatial conv2-5 | Both conv1 + both fc | 85-90% | 12-15h |

**Recommendation:** Start with temporal-only, add `--unfreeze_temporal_backbone` if you have time.

---

**Bottom Line:** Fine-tuning is about balance - leverage pre-trained knowledge (freeze) while adapting to the new task (train). For Two-Stream on UCF-101, training just the temporal classifier gets you 80%+ accuracy in a few hours. That's the magic of transfer learning! ğŸ¯